{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones iniciales (Grafica y Equipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";\n",
    "\n",
    "#Si se esta trabajando en colab la variable debe quedar en falso\n",
    "SERVER = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instaladas python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "if not SERVER:\n",
    "    !pip -q install -U nltk==3.4.5\n",
    "    %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establezco el crecimiento de la grafica a medida que necesite memoria\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propias y externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "if SERVER:\n",
    "    !git pull\n",
    "else:\n",
    "    #Archivos py\n",
    "    !git clone https://github.com/JefeLitman/SignLanguageTranslation_SLT.git > /dev/null\n",
    "    #Organizacion archivos\n",
    "    !mv /content/SignLanguageTranslation_SLT/utils /content/\n",
    "    !mv /content/SignLanguageTranslation_SLT/models /content/\n",
    "    !mv /content/SignLanguageTranslation_SLT/metrics /content/\n",
    "    #Elimino la carpeta sobrante\n",
    "    !rm -rf /content/SignLanguageTranslation_SLT\n",
    "#DatasetsLoaderUtils\n",
    "!wget -q https://raw.githubusercontent.com/JefeLitman/VideoDataGenerator/master/DatasetsLoaderUtils.py -O DatasetsLoaderUtils.py\n",
    "!mv DatasetsLoaderUtils.py utils/DatasetsLoaderUtils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess_data import preprocessing_paths, preprocessing_sentences, table_paths_dataset\n",
    "from utils.build_tf_data import build_datasets\n",
    "from metrics.losses import SparseCategoricalCrossentropy_mask\n",
    "from models import compute_features, encoder, decoder, reduce_features, self_attentions, st_attentions, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SERVER:\n",
    "    !rm -rf /content/sample_data\n",
    "    # Se esta descargando la data de Boston201\n",
    "    !wget --quiet --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Ph_Ys3O_vI93WeTkDqr5h6kTJm0CZ0Ub' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Ph_Ys3O_vI93WeTkDqr5h6kTJm0CZ0Ub\" -O boston201.zip && rm -rf /tmp/cookies.txt\n",
    "    !unzip -q boston201.zip\n",
    "    !rm boston201.zip\n",
    "    !wget -q https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip -O word_vectors.zip\n",
    "    !unzip -q word_vectors.zip\n",
    "    !rm word_vectors.zip\n",
    "    # Monto el drive para poder tener donde guardar los datos\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo SLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = namedtuple('Args', 'max_len_sentence data pretrained prefetch_batch_buffer unitsEmbedding vocab_size nIters videos_path rnnUnits dropout recurrent_dropout inputShape optimizer type_frames batchSize epochs lr momentum decay wDecay path2save name')\n",
    "\n",
    "args = Args(max_len_sentence=15,\n",
    "            videos_path='../DataSets/boston201',#'/content/boston201',\n",
    "            rnnUnits=256,\n",
    "            unitsEmbedding=300,\n",
    "            vocab_size=150,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0.2,\n",
    "            inputShape=(32, 112, 112, 3),\n",
    "            pretrained=None,#'vgg16',\n",
    "            optimizer='adam',\n",
    "            type_frames='jpg/',\n",
    "            batchSize=1,\n",
    "            epochs=20,\n",
    "            nIters=10.0,\n",
    "            lr=0.001,\n",
    "            momentum=0.99,\n",
    "            decay=0.1,\n",
    "            wDecay=0.0005,\n",
    "            path2save='path_to_save_model_results',\n",
    "            name='SLT_Model',\n",
    "            data= '../DataSets/boston201/data/', #'/content/boston201/data/',\n",
    "            prefetch_batch_buffer = 5\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training file ...\n",
      "training on train sentences to make the vocab ...\n",
      "training text to index sequences ..\n",
      "training index sequences to padded sequences ..\n",
      "Computing same steps over dev and test sequences\n",
      "Completed\n",
      "Completed\n",
      "Creating the table paths for flow_from_tablePaths ..\n"
     ]
    }
   ],
   "source": [
    "paths_translation = [args.data+'translations.train',  \n",
    "                         args.data+'translations.test']\n",
    "paths_videos = [args.data+'pathsigns.train', \n",
    "                    args.data+'pathsigns.test']\n",
    "\n",
    "# Processing sentences and paths\n",
    "preprocessed_sentences, vocab = preprocessing_sentences(paths_translation, max_len=args.max_len_sentence)\n",
    "preprocessed_paths = preprocessing_paths(paths_videos, path2videos=args.videos_path, type_=args.type_frames)\n",
    "\n",
    "#Creating table paths\n",
    "table_paths=table_paths_dataset(preprocessed_paths, preprocessed_sentences)\n",
    "\n",
    "#Get the train, test and dev data\n",
    "train_data, test_data, dev_data = build_datasets(table_paths, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion y estructuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas de la red\n",
    "input_video = tf.keras.Input(shape=args.inputShape, batch_size=args.batchSize, name=\"input_video\")\n",
    "input_words = tf.keras.Input(shape=[args.max_len_sentence-1], batch_size=args.batchSize, name=\"input_words\")\n",
    "\n",
    "# Compute features and reduce features\n",
    "x = compute_features.compute_features_v1_0(input_video, weight_decay=tf.keras.regularizers.l2(args.wDecay))\n",
    "x = reduce_features.reduce_features_v1_2(x)\n",
    "\n",
    "#Encoder module and self attention\n",
    "x1, rnn1_states, rnn2_states = encoder.encoder_v1_1(x, args.rnnUnits, args.unitsEmbedding, \n",
    "    args.dropout, args.recurrent_dropout)\n",
    "x1 = self_attentions.self_attention_v1_0(x1)\n",
    "\n",
    "#Decoder module\n",
    "x2 = decoder.decoder_v1_0(input_words, rnn1_states, rnn2_states, args.rnnUnits, args.unitsEmbedding, \n",
    "    args.vocab_size, args.dropout, args.recurrent_dropout)\n",
    "\n",
    "# Spatio Temporal attention\n",
    "x3 = st_attentions.st_attention_v1_4_1(x2, x1, x)\n",
    "\n",
    "# Output of the network\n",
    "x = output.output_v1_0(x2, x3, args.vocab_size)\n",
    "\n",
    "model = tf.keras.Model(inputs=(input_video, input_words), outputs=x, name=args.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, to_file=args.name+'.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = args.lr\n",
    "    drop = args.decay\n",
    "    epochs_drop = args.nIters\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate_sheduler = tf.keras.callbacks.LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.optimizer == 'adam':\n",
    "    opt = tf.keras.optimizers.Adam(\n",
    "        lr=args.lr, \n",
    "        beta_1=0.9, \n",
    "        beta_2=0.999, \n",
    "        epsilon=1e-08, \n",
    "        decay=0.0, \n",
    "        clipnorm=1., \n",
    "        clipvalue=5)\n",
    "\n",
    "elif args.optimizer == 'sgd':\n",
    "    opt = tf.keras.optimizers.SGD(\n",
    "        lr=args.lr, \n",
    "        decay=0, \n",
    "        momentum=args.momentum, \n",
    "        nesterov=True, \n",
    "        clipnorm=1., \n",
    "        clipvalue=0.5)\n",
    "\n",
    "elif args.optimizer == 'rsmprop':\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=args.lr) \n",
    "                         #clipnorm=1., \n",
    "                         #clipvalue=0.5)      \n",
    "else:\n",
    "    raise ValueError('You must specify a valid optimizer for model. The only optmizers available are: '\n",
    "                    '\"adam\", \"sgd\" or \"rmsprop\". The optmizer given was: '+str(args.optimizer))\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,l in train_data.take(1):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=SparseCategoricalCrossentropy_mask, metrics=[acc])\n",
    "model.fit_generator(generator=training_generator,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=4,\n",
    "                              epochs=args.epochs,\n",
    "                              callbacks=callbacks_list)#validation_data=validation_generator,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
