{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Initial config for notebooks { display-mode: \"form\" }\n",
    "import os\n",
    "from getpass import getpass\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = input('Select the GPU ID to work or -1 to CPU: ')\n",
    "\n",
    "# Auto detecting Colab or server:\n",
    "if os.getcwd() == \"/content\":\n",
    "    os.environ[\"SERVER\"] = \"0\"\n",
    "else:\n",
    "    os.environ[\"SERVER\"] = \"1\"\n",
    "\n",
    "if int(os.getenv('SERVER')):\n",
    "    !git pull\n",
    "else:\n",
    "    # Install required libraries for Colab\n",
    "    !pip -q install -U nltk==3.4.5\n",
    "    # Import the encoder function to URL's\n",
    "    import urllib.parse\n",
    "    # Delete folders in /content/\n",
    "    for folder in os.listdir('/content/'):\n",
    "        if folder == \"drive\":\n",
    "            raise ValueError('You have the drive folder mounted, reset the '\n",
    "                'the machine to fabric state to work again.')\n",
    "        else:\n",
    "            os.system(\"rm -rf /content/\"+folder)\n",
    "    # User credentials\n",
    "    os.environ[\"USER\"] = input('Github username: ')\n",
    "    os.environ[\"PASS\"] = urllib.parse.quote(getpass('Password: '))\n",
    "    # Py archives\n",
    "    !git clone \"https://$USER:$PASS@github.com/JefeLitman/SignLanguageTranslation_SLT.git\" .\n",
    "#DatasetsLoaderUtils\n",
    "!wget -q https://raw.githubusercontent.com/JefeLitman/VideoDataGenerator/master/DatasetsLoaderUtils.py -O DatasetsLoaderUtils.py\n",
    "!mv DatasetsLoaderUtils.py utils/DatasetsLoaderUtils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "\n",
    "from utils.preprocess_data import preprocessing_paths, preprocessing_sentences, table_paths_dataset\n",
    "from utils.DatasetsLoaderUtils import flow_from_tablePaths\n",
    "from utils.results import save_predictions, calculate_metrics_results\n",
    "from metrics.losses import SparseCategoricalCrossentropy_mask\n",
    "from metrics.accuracy import real_acc\n",
    "from models import compute_features, encoder, decoder, reduce_features, self_attentions, st_attentions, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") != '-1':\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bool(os.getenv('SERVER')):\n",
    "    from utils import download_data\n",
    "    download_data.boston201()\n",
    "    download_data.embedding_word_vectors()\n",
    "    # Mount drive to save models and results\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model SLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = namedtuple('Args', 'max_len_sentence data pretrained prefetch_batch_buffer unitsEmbedding vocab_size nIters videos_path rnnUnits dropout recurrent_dropout inputShape optimizer type_frames batchSize epochs lr momentum decay wDecay path2save name')\n",
    "\n",
    "args = Args(max_len_sentence=15,\n",
    "            videos_path='../DataSets/boston201',#'/content/data/boston201',\n",
    "            rnnUnits=256,\n",
    "            unitsEmbedding=300,\n",
    "            vocab_size=150,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0.2,\n",
    "            inputShape=(32, 112, 112, 3),\n",
    "            pretrained=None,#'vgg16',\n",
    "            optimizer='adam',\n",
    "            type_frames='jpg/',\n",
    "            batchSize=2,\n",
    "            epochs=20,\n",
    "            nIters=10.0,\n",
    "            lr=0.001,\n",
    "            momentum=0.99,\n",
    "            decay=0.1,\n",
    "            wDecay=0.0005,\n",
    "            path2save='../Saved_Models/', #'/content/drive/My Drive/Models/SLT/<experiment_folder>'\n",
    "            name='SLT_Model',\n",
    "            data= '../DataSets/boston201/data/', #'/content/data/boston201/data/',\n",
    "            prefetch_batch_buffer = -1\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seeds for replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8128)\n",
    "np.random.seed(8128)\n",
    "tf.random.set_seed(8128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_translation = [args.data+'translations.train',  \n",
    "                         args.data+'translations.test']\n",
    "paths_videos = [args.data+'pathsigns.train', \n",
    "                    args.data+'pathsigns.test']\n",
    "\n",
    "# Processing sentences and paths\n",
    "preprocessed_sentences, vocab = preprocessing_sentences(paths_translation, max_len=args.max_len_sentence)\n",
    "preprocessed_paths = preprocessing_paths(paths_videos, path2videos=args.videos_path, type_=args.type_frames)\n",
    "\n",
    "#Creating table paths\n",
    "table_paths=table_paths_dataset(preprocessed_paths, preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building tf.data.Dataset and data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Callbacks for methods { display-mode: \"form\" }\n",
    "from utils.data_augmentation import frame_sampling\n",
    "\n",
    "def train_gen_sampling():\n",
    "    train_gen = raw_data.data_generator(1, args.inputShape[-1])\n",
    "    for v, l in train_gen:\n",
    "        s = np.r_[[int(j) for j in (raw_data.to_class[l]).split(\", \")]]\n",
    "        for new_v in frame_sampling(v, args.inputShape[0]):\n",
    "            yield (new_v, s[:-1]), s[1:]\n",
    "\n",
    "def test_gen_sampling():\n",
    "    test_gen = raw_data.data_generator(2, args.inputShape[-1])\n",
    "    for v, l in test_gen:\n",
    "        s = np.r_[[int(j) for j in (raw_data.to_class[l]).split(\", \")]]\n",
    "        for new_v in frame_sampling(v, args.inputShape[0]):\n",
    "            yield (new_v, s[:-1]), s[1:]\n",
    "\n",
    "def scale_0_255(data, label):\n",
    "    return (data[0]/255., data[1]), label\n",
    "\n",
    "def scale_minus1_1(data, label):\n",
    "    return ((data[0]- 127.5) / 127.5, data[1]), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = flow_from_tablePaths(table_paths, lambda x: x, args.inputShape[1:3])\n",
    "\n",
    "train_data = tf.data.Dataset.from_generator(train_gen_sampling, ((tf.float32, tf.int64), tf.int64),\n",
    "    ((args.inputShape, args.max_len_sentence-1), args.max_len_sentence-1))\n",
    "\n",
    "train_data = train_data.cache().map(scale_0_255, -1)\n",
    "train_data = train_data.shuffle(318, reshuffle_each_iteration=True).batch(args.batchSize)\n",
    "train_data = train_data.prefetch(args.prefetch_batch_buffer)\n",
    "\n",
    "test_data = tf.data.Dataset.from_generator(test_gen_sampling, ((tf.float32, tf.int64), tf.int64),\n",
    "    ((args.inputShape, args.max_len_sentence-1), args.max_len_sentence-1))\n",
    "\n",
    "test_data = test_data.cache().map(scale_0_255, -1)\n",
    "test_data = test_data.shuffle(84, reshuffle_each_iteration=True).batch(args.batchSize).prefetch(args.prefetch_batch_buffer)\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas del encoder\n",
    "input_video = tf.keras.Input(shape=args.inputShape, name=\"input_video\")\n",
    "\n",
    "# Compute features and reduce features\n",
    "x = compute_features.compute_features_v1_0(input_video, weight_decay=tf.keras.regularizers.l2(args.wDecay))\n",
    "x = reduce_features.reduce_features_v1_2(x)\n",
    "\n",
    "# Encoder module and self attention\n",
    "x1, lstm1_enc_h, lstm1_enc_c, lstm2_enc_h, lstm2_enc_c = encoder.encoder_v1_1(x, args.rnnUnits, \n",
    "    args.unitsEmbedding, args.dropout, args.recurrent_dropout)\n",
    "x1 = self_attentions.self_attention_v1_0(x1)\n",
    "\n",
    "# Modelo encoder\n",
    "encoder = tf.keras.Model(inputs=[input_video], \n",
    "    outputs=[x, x1, lstm1_enc_h, lstm1_enc_c, lstm2_enc_h, lstm2_enc_c], \n",
    "    name=\"SLT_encoder\")\n",
    "\n",
    "# Entradas del decoder\n",
    "input_word = tf.keras.Input(shape=[1], name=\"input_word\") # Entra palabra por palabra\n",
    "input_x = tf.keras.Input(shape=x.shape[1:], name=\"input_feat_enc\") # Entrada de las reduce features del encoder\n",
    "input_x1 = tf.keras.Input(shape=x1.shape[1:], name=\"input_sea_enc\") # Entrada de la self attention del encoder\n",
    "input_lstm1_h = tf.keras.Input(shape=[args.rnnUnits], name=\"input_lstm1_h\")\n",
    "input_lstm1_c = tf.keras.Input(shape=[args.rnnUnits], name=\"input_lstm1_c\")\n",
    "input_lstm2_h = tf.keras.Input(shape=[args.rnnUnits], name=\"input_lstm2_h\")\n",
    "input_lstm2_c = tf.keras.Input(shape=[args.rnnUnits], name=\"input_lstm2_c\")\n",
    "\n",
    "# Decoder module\n",
    "x2, lstm1_dec_h, lstm1_dec_c, lstm2_dec_h, lstm2_dec_c = decoder.decoder_v1_0(input_word, input_lstm1_h, \n",
    "    input_lstm1_c, input_lstm2_h, input_lstm2_c, args.rnnUnits, args.unitsEmbedding, \n",
    "    args.vocab_size, args.dropout, args.recurrent_dropout)\n",
    "\n",
    "# Spatio Temporal attention\n",
    "x3 = st_attentions.st_attention_v1_4_1(x2, input_x1, input_x)\n",
    "\n",
    "# Output of the network\n",
    "x_final = output.output_v1_0(x2, x3, args.vocab_size)\n",
    "\n",
    "decoder = tf.keras.Model(inputs=[input_word, input_lstm1_h, input_lstm1_c, input_lstm2_h, input_lstm2_c, \n",
    "    input_x, input_x1], \n",
    "    outputs=[x_final, lstm1_dec_h, lstm1_dec_c, lstm2_dec_h, lstm2_dec_c], \n",
    "    name=\"SLT_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(decoder, to_file='SLT_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "if args.optimizer == 'adam':\n",
    "    opt = tf.keras.optimizers.Adam(\n",
    "        lr=args.lr, \n",
    "        beta_1=0.9, \n",
    "        beta_2=0.999, \n",
    "        epsilon=1e-08, \n",
    "        decay=0.0, \n",
    "        clipnorm=1., \n",
    "        clipvalue=5)\n",
    "\n",
    "elif args.optimizer == 'sgd':\n",
    "    opt = tf.keras.optimizers.SGD(\n",
    "        lr=args.lr, \n",
    "        decay=0, \n",
    "        momentum=args.momentum, \n",
    "        nesterov=True, \n",
    "        clipnorm=1., \n",
    "        clipvalue=0.5)\n",
    "\n",
    "elif args.optimizer == 'rsmprop':\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=args.lr) \n",
    "                         #clipnorm=1., \n",
    "                         #clipvalue=0.5)      \n",
    "else:\n",
    "    raise ValueError('You must specify a valid optimizer for model. The only optmizers available are: '\n",
    "                    '\"adam\", \"sgd\" or \"rmsprop\". The optmizer given was: '+str(args.optimizer))\n",
    "# Metrics\n",
    "loss=SparseCategoricalCrossentropy_mask\n",
    "#acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "acc = real_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and eval step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder, decoder models must be defined before hand with that names.\n",
    "# In the same way opt, loss, acc and acc_mask are defined before hand with that names.\n",
    "# Finally vocab must be define before hand too for eval step\n",
    "\n",
    "def train_step(video, sentence, target):\n",
    "    \"\"\"Function to make a train step with encoder and decoder models.\n",
    "    Args:\n",
    "        video: The video batched to insert in encoder model.\n",
    "        sentence: The sentence batched to insert in the decoder model word by word.\n",
    "        target: The objetive batched sentence to predict with the model.\n",
    "    \"\"\"\n",
    "    # Set the model in training phase\n",
    "    tf.keras.backend.set_learning_phase(True)\n",
    "    sentence_loss = 0\n",
    "    predictions = []\n",
    "    with tf.GradientTape() as tape:\n",
    "        red_feat, enc_output, lstm1_h, lstm1_c, lstm2_h, lstm2_c = encoder(video)\n",
    "        for word_idx in tf.range(0, sentence.shape[1]):\n",
    "            prediction, lstm1_h, lstm1_c, lstm2_h, lstm2_c = decoder([tf.expand_dims(sentence[:,word_idx], axis=1), \n",
    "                lstm1_h, lstm1_c, lstm2_h, lstm2_c, red_feat, enc_output])\n",
    "\n",
    "            sentence_loss += loss(target[:, word_idx], prediction)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(sentence_loss, variables)\n",
    "    opt.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return sentence_loss, tf.concat(predictions, axis=1)\n",
    "\n",
    "def eval_step(video):\n",
    "    \"\"\"Function to make a eval step with encoder and decoder models.\n",
    "    Args:\n",
    "        video: The video batched to insert in encoder model.\n",
    "    \"\"\"\n",
    "    # Set the model in training phase\n",
    "    tf.keras.backend.set_learning_phase(False)\n",
    "    predictions = []\n",
    "    red_feat, enc_output, lstm1_h, lstm1_c, lstm2_h, lstm2_c = encoder(video)\n",
    "    word = vocab.word_index['<s>']\n",
    "    for _ in tf.range(0, args.max_len_sentence-1):\n",
    "        prediction, lstm1_h, lstm1_c, lstm2_h, lstm2_c = decoder([tf.reshape(word, [1,1]), \n",
    "            lstm1_h, lstm1_c, lstm2_h, lstm2_c, red_feat, enc_output])\n",
    "\n",
    "        word = tf.squeeze(tf.argmax(prediction, axis=1))\n",
    "        predictions.append(word)\n",
    "        if tf.equal(vocab.index_word[word], '</s>'):\n",
    "            break\n",
    "    \n",
    "    return tf.concat(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=opt, loss=SparseCategoricalCrossentropy_mask, metrics=[real_acc,\n",
    "#     tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    # Train phase\n",
    "    step = 1\n",
    "    for xy, y_true in train_data.take(1):\n",
    "        batch_loss, batch_predictions = train_step(xy[0], xy[1], y_true)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(\"Step:\", step*args.batchSize, \"Learning rate:\", opt.lr.numpy())\n",
    "        print(\"Epoch:\", epoch+1, \"Train batch:\", step)\n",
    "        print(\"Train_Loss: \",batch_loss.numpy())\n",
    "        print(\"Train_Accuracy: \",acc(y_true, batch_predictions).numpy())\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predictions = train_step(xy[0], xy[1], y_true)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(y_true, tf.concat(batch_predictions, axis=1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_indexes = tf.argmax(batch_predictions, axis=-1)\n",
    "    \n",
    "mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "mask = tf.cast(mask, dtype=pred_indexes.dtype)\n",
    "\n",
    "pred_indexes = tf.multiply(pred_indexes, mask)\n",
    "\n",
    "equals = tf.math.equal(tf.cast(y_true, pred_indexes.dtype), pred_indexes)\n",
    "# return tf.math.reduce_mean(tf.cast(equals, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax(batch_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax(tf.concat(batch_predictions, axis=1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = decoder.get_layer(\"dense_qk_sta\").output\n",
    "b = decoder.get_layer(\"input_feat_enc\").output\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(os.path.join(args.path2save, \"trained_encoder.h5\"), include_optimizer=False)\n",
    "decoder.save(os.path.join(args.path2save, \"trained_decider.h5\"), include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning (Optional to the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Boston dataset doesn't have dev dision so there is not finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for result to work (This generators are needed to compability)\n",
    "def train_gen_sampling():\n",
    "    i = 0\n",
    "    train_gen = raw_data.data_generator(1, args.inputShape[-1])\n",
    "    train = table_paths[table_paths[:,1] == \"train\"]\n",
    "    \n",
    "    for v, l in train_gen:\n",
    "        s = np.r_[[int(j) for j in (raw_data.to_class[l]).split(\", \")]]\n",
    "        p = train[i][0]\n",
    "        i += 1\n",
    "        for new_v in [frame_sampling(v, args.inputShape[0])[0]]:\n",
    "            yield new_v, s, p\n",
    "train_data = tf.data.Dataset.from_generator(train_gen_sampling, (tf.float32, tf.int64, tf.string)).batch(1)\n",
    "\n",
    "def test_gen_sampling():\n",
    "    i = 0\n",
    "    test_gen = raw_data.data_generator(2, args.inputShape[-1])\n",
    "    test = table_paths[table_paths[:,1] == \"test\"]\n",
    "    for v, l in test_gen:\n",
    "        s = np.r_[[int(j) for j in (raw_data.to_class[l]).split(\", \")]]\n",
    "        p = test[i][0]\n",
    "        i += 1\n",
    "        for new_v in [frame_sampling(v, args.inputShape[0])[0]]:\n",
    "            yield new_v, s, p\n",
    "test_data = tf.data.Dataset.from_generator(test_gen_sampling, (tf.float32, tf.int64, tf.string)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = save_predictions(model, args.path2save, vocab, args, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "calculate_metrics_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Upload your changes { display-mode: \"form\" }\n",
    "if not int(os.getenv('SERVER')):\n",
    "    !git config --global user.email \"$USER@github.com\"\n",
    "    !git config --global user.name \"$USER\"\n",
    "!git add -A *\n",
    "os.environ[\"COMMIT\"] = input(\"Insert the name for your changes: \")\n",
    "!git commit -m  \"$COMMIT\"\n",
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
